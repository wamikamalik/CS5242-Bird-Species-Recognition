# -*- coding: utf-8 -*-
"""mobile_net.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/124oMtku7lFNIayqEac2O2pIW7AvhHji8

## Loading the Data
"""

# # For Google Colaboratory
# import sys, os
# if 'google.colab' in sys.modules:

#     # mount google drive
#     from google.colab import drive
#     drive.mount('/content/gdrive')
#     path_to_file = '/content/gdrive/My Drive/CS5242/Project/' # Update this path depending on where data is uploaded on your Google Drive.
#     print(path_to_file)
#     # move to Google Drive directory
#     os.chdir(path_to_file)
#     !pwd

# !ls

import pandas as pd
from torch.utils.data import DataLoader, Subset
from torchvision.datasets import ImageFolder
from torchvision.transforms import transforms
from sklearn.model_selection import train_test_split
import zipfile
import os
import csv
from torch.utils.data import ConcatDataset
import numpy as np
# Extra info for logging
extra = 'mobile_net_3.py + normalised'

# Load the metadata
metadata = pd.read_csv('meta_data.csv')
metadata['augmented_images_more'] = metadata['augmented_image_name'].str.replace('augmented_images','augmented_images_more')
metadata['augmented_image_nocrop_name'] = metadata['augmented_image_name'].str.replace('augmented_images','augmented_images_nocrop')

# Create a dictionary mapping from image file name to is_training_image

# Only add training images for augmented
temp = metadata[metadata.is_training_image == 1]

is_training_image = dict(zip(temp.augmented_image_name, temp.is_training_image))   # original augmentation
is_training_image.update(zip(temp.augmented_images_more, temp.is_training_image))  # more augmentation
is_training_image.update(zip(temp.augmented_image_nocrop_name, temp.is_training_image)) # augmented but no crop to bbox

# Add original data
# Test will be from original images (not cropped, only resize to 224,224)
is_training_image.update(zip(metadata.image_name, metadata.is_training_image))

# Define the transformation
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Function to load or extract dataset
def load_or_extract(directory, zip_file):
    if os.path.isdir(directory):
        print(f"Directory {directory} exists, skipping zip extraction.")
    else:
        print(f"Directory {directory} does not exist, extracting zip file {zip_file}...")
        with zipfile.ZipFile(zip_file, 'r') as zip_ref:
            zip_ref.extractall("./")
        print(f"Extracted {zip_file}.")

# Load or extract both datasets
load_or_extract("./augmented_images", "./augmented_images.zip")
load_or_extract("./images", "./images.zip")
load_or_extract("./augmented_images_more","./augmented_images_more.zip")
load_or_extract("./augmented_images_nocrop","./augmented_images_nocrop.zip")

# Load datasets
dataset_augmented = ImageFolder("./augmented_images", transform=transform)
dataset_images = ImageFolder("./images", transform=transform)
dataset_augmented_more = ImageFolder("./augmented_images_more", transform=transform)
dataset_augmented_nocrop = ImageFolder("./augmented_images_nocrop", transform=transform)


# Combine datasets
all_classes = sorted(set(dataset_images.classes + dataset_augmented.classes + dataset_augmented_more.classes + dataset_augmented_nocrop.classes))
combined_dataset = ConcatDataset([dataset_images, dataset_augmented, dataset_augmented_more, dataset_augmented_nocrop])
combined_dataset.classes = all_classes
print(combined_dataset)

def get_combined_indices(combined_dataset, is_training_image):
    train_indices, test_indices = [], []
    offset = 0  # Offset to account for different datasets in ConcatDataset
    for dataset in combined_dataset.datasets:
        for i, (img, _) in enumerate(dataset.imgs):
            # Construct relative path as used in is_training_image
            rel_path = "./" + os.path.normpath(img)
            if rel_path in is_training_image:  # Check if the image is in the dictionary
                if is_training_image[rel_path] == 1:
                    train_indices.append(i + offset)  # Image is for training
                else:
                    test_indices.append(i + offset)  # Image is for testing
        offset += len(dataset)  # Update offset for the next dataset
    return train_indices, test_indices


# Get combined train and test indices
#train_indices, test_indices = get_combined_indices(combined_dataset, is_training_image)
#test_indices, val_indices = train_test_split(test_indices, test_size=0.2, random_state=42)
#print(f"Number of training indices: {len(train_indices)}")
#print(f"Number of testing indices: {len(test_indices)}")
#print(f"Number of testing indices: {len(val_indices)}")

# Save the indices to .npy files
#np.save('train_indices.npy', train_indices)
#np.save('test_indices.npy', test_indices)
#np.save('val_indices.npy', val_indices)

# Load indices from .npy files (demonstration)
train_indices = np.load('train_indices.npy')
val_indices = np.load('val_indices.npy')
test_indices = np.load('test_indices.npy')

# Create training and testing subsets
train_dataset = Subset(combined_dataset, train_indices)
test_dataset = Subset(combined_dataset, test_indices)
val_dataset = Subset(combined_dataset, val_indices)

print("Creating the data loaders...")
# Create the data loaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)


"""## Split Training Dataset into train and validation"""

# from torch.utils.data import random_split

# # Define the size of the validation set as 20% of the original test dataset
# val_size = int(0.2 * len(test_dataset))
# new_test_size = len(test_dataset) - val_size

# # Split the original test dataset into new smaller test and validation sets
# new_test_dataset, val_dataset = random_split(test_dataset, [new_test_size, val_size])

# Create the data loaders
# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
# # Update the test_loader to use the new_test_dataset
# test_loader = DataLoader(new_test_dataset, batch_size=32, shuffle=False)

print("Training set size: ", len(train_dataset))
print("Validation set size: ", len(val_dataset))
print("Test set size: ", len(test_dataset))

import torchvision.utils as vutils

"""## MobileNet Transfer Learning Model Creation"""

import torch
from torch import nn
from torchvision.models import mobilenet_v2
import torch.nn.functional as F

def accuracy(outputs, labels):
    _, preds = torch.max(outputs, dim=1)
    return torch.tensor(torch.sum(preds == labels).item() / len(preds))

class BaseModel(nn.Module):
    def __init__(self):
        super(BaseModel, self).__init__()

    def training_step(self, batch):
        raise NotImplementedError

    def validation_step(self, batch):
        raise NotImplementedError

    def epoch_end(self, epoch, result):
        print("Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}".format(
            epoch, result['train_loss'], result['val_loss']))

class MobileNetModel(BaseModel):
    def __init__(self, num_classes):
        super().__init__()
        self.network = mobilenet_v2(pretrained=True)

        # No freezing
        # for param in self.network.parameters():
        #     param.requires_grad = True

        # Freeze all the parameters of the model
        for param in self.network.parameters():
            param.requires_grad = False

        # # Unfreeze the last five layers
        # for param in list(self.network.parameters())[-5:]:
        #     param.requires_grad = True

        # Unfreeze Batch Normalization
        for module in self.network.modules():
            if isinstance(module, nn.BatchNorm2d):
                for param in module.parameters():
                    param.requires_grad = True

        # Unfreeze last layer
        for param in self.network.features[-1].parameters():
            param.requires_grad = True
                    
        # Replace the classifier with a custom one
        num_ftrs = self.network.classifier[1].in_features
        self.network.classifier = nn.Sequential(
            nn.Dropout(0.5), 
		    nn.Linear(num_ftrs, num_classes)
            )
        # self.network.classifier[1] = nn.Linear(num_ftrs, num_classes)

    def forward(self, xb):
        return self.network(xb)

    def training_step(self, batch):
        images, labels = batch
        out = self(images)                  # Generate predictions
        loss = F.cross_entropy(out, labels) # Calculate loss
        return loss

    def validation_step(self, batch):
        images, labels = batch
        out = self(images)                    # Generate predictions
        loss = F.cross_entropy(out, labels)   # Calculate loss
        acc = accuracy(out, labels)           # Calculate accuracy
        return {'val_loss': loss.detach(), 'val_acc': acc}

"""## Training the Model"""

import torch
import numpy as np
from torch.utils.data import DataLoader

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
num_classes = len(combined_dataset.classes)
model = MobileNetModel(num_classes).to(device)

def fit(epochs, lr, train_loader, val_loader, optimizer_class):
    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
    optimizer = optimizer_class(model.parameters(), lr)
    best_val_loss = float('inf')
    best_val_acc = 0 
    for epoch in range(epochs):
        # Training Phase
        model.train()
        train_losses = []
        train_accs = []
        print("Starting epoch ", epoch+1, " of ", epochs)
        for batch_idx, (inputs, labels) in enumerate(train_loader):
            inputs = inputs.to(device)
            labels = labels.to(device)
            # Debugging print statements
            # print(f"Batch {batch_idx}: Inputs device - {inputs.device}, Labels device - {labels.device}, Model device - {next(model.parameters()).device}")

            optimizer.zero_grad()
            loss = model.training_step((inputs, labels))  # Streamlined call
            train_losses.append(loss.item())

            loss.backward()
            optimizer.step()

            # Compute accuracy for debugging
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            acc = torch.sum(preds == labels.data) / len(labels)
            train_accs.append(acc.item())

        # Record training loss and accuracy
        history['train_loss'].append(np.mean(train_losses))
        history['train_acc'].append(np.mean(train_accs))

        # Validation phase
        model.eval()
        val_losses = []
        val_accs = []
        with torch.no_grad():
            for batch_idx, (inputs, labels) in enumerate(val_loader):
                inputs = inputs.to(device)
                labels = labels.to(device)
                # Debugging print statements for validation phase
                # print(f"Validation Batch {batch_idx}: Inputs device - {inputs.device}, Labels device - {labels.device}")

                validation_step_output = model.validation_step((inputs, labels))
                val_losses.append(validation_step_output['val_loss'].item())
                val_accs.append(validation_step_output['val_acc'].item())

        # Record validation loss and accuracy
        epoch_val_loss = np.mean(val_losses)
        history['val_loss'].append(epoch_val_loss)
        history['val_acc'].append(np.mean(val_accs))
        print(f'Epoch {epoch+1}/{epochs}, train loss: {np.mean(train_losses):.4f}, val loss: {epoch_val_loss:.4f}, train acc: {np.mean(train_accs):.4f}, val acc: {np.mean(val_accs):.4f}')
        
        if epoch_val_loss < best_val_loss:
            print(f"Validation loss decreased ({best_val_loss:.6f} --> {epoch_val_loss:.6f}).  Saving model ...")
            best_val_loss = epoch_val_loss
            torch.save(model.state_dict(), 'model_lowest_val_loss.pth')
            print(f"New lowest validation loss: {best_val_loss:.6f}. Model saved as model_lowest_val_loss.pth")
        
        if np.mean(val_accs) > best_val_acc:
            best_val_acc = np.mean(val_accs)
            torch.save(model.state_dict(), 'model_highest_val_acc.pth')
            print(f"New highest validation accuracy: {best_val_acc:.4f}. Model saved as model_highest_val_acc.pth")

    return history

num_epochs = 60
opt_func = torch.optim.Adam
lr = 0.001

history = fit(num_epochs, lr, train_loader, val_loader, opt_func)

import matplotlib.pyplot as plt

def plot_history(history):
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))

    ax1.plot(history['train_loss'], label='train loss')
    ax1.plot(history['val_loss'], label='validation loss')
    ax1.set_xlabel('Epochs')
    ax1.set_ylabel('Loss')
    ax1.legend()

    ax2.plot(history['train_acc'], label='train accuracy')
    ax2.plot(history['val_acc'], label='validation accuracy')
    ax2.set_xlabel('Epochs')
    ax2.set_ylabel('Accuracy')
    ax2.legend()

    plt.tight_layout()
    plt.savefig('mobilenet_train_val_acc_loss.png')

plot_history(history)

"""## Test the Model"""

def test_model(model, test_loader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    test_accuracy = 100 * correct / total
    print('Test Accuracy of the model on the test images: {} %'.format(test_accuracy))
    return test_accuracy

import csv
import pandas as pd

def log_training_session(log_file_path, session_details):
    # Check if log file exists
    try:
        log_df = pd.read_csv(log_file_path)
    except FileNotFoundError:
        log_df = pd.DataFrame(columns=['num_epochs', 'optimizer', 'learning_rate', 'train_loss', 'val_loss', 'train_acc', 'val_acc', 'test_acc', 'extra'])
    
    # Append new session details
    log_df = log_df.append(session_details, ignore_index=True)
    
    # Save updated log to CSV
    log_df.to_csv(log_file_path, index=False)
    
    return log_df


def evaluate_and_compare_models(model, test_loader, device, log_file_path, session_details):
    # Paths to models saved based on validation accuracy and loss
    models_paths = {
        'accuracy': 'model_highest_val_acc.pth',
        'loss': 'model_lowest_val_loss.pth'
    }
    
    test_performances = {}
    
    for criterion, path in models_paths.items():
        # Load model state
        model.load_state_dict(torch.load(path, map_location=device))
        print(f"Loaded the model based on {criterion} for testing.")
        
        # Evaluate model on test set
        test_acc = test_model(model, test_loader, device)
        print(f"Test accuracy for model based on {criterion}: {test_acc}%")
        
        # Store the test performance
        test_performances[criterion] = test_acc
    
    # Determine the best model based on test accuracy
    best_criterion = max(test_performances, key=test_performances.get)
    best_test_acc = test_performances[best_criterion]
    session_details['test_acc'] = best_test_acc
    
    # Update the session log and determine if this is the best model ever based on test accuracy
    log_df = log_training_session(log_file_path, session_details)
    
    if best_test_acc >= log_df['test_acc'].max():
        print('New highest test accuracy achieved. Saving the best model...')
        best_model_path = models_paths[best_criterion]
        model.load_state_dict(torch.load(best_model_path, map_location=device))
        torch.save(model.state_dict(), 'mobilenet_best.pth')
        print(f"Model saved as mobilenet_best.pth with a test accuracy of {best_test_acc}%. Based on {best_criterion}.")
    else:
        print('Higher or equal test accuracy model exists. Current model not saved.')
    
    return best_test_acc


# Define session details
session_details = {
    'num_epochs': num_epochs,
    'optimizer': opt_func,
    'learning_rate': lr,
    'train_loss': history['train_loss'][-1],
    'val_loss': history['val_loss'][-1],
    'train_acc': history['train_acc'][-1],
    'val_acc': history['val_acc'][-1],
    'extra' : extra,
}

# Log file path
log_file_path = 'training_log.csv'

# Evaluate the model and decide on saving
evaluate_and_compare_models(model, test_loader, device, log_file_path, session_details)

    
# test_model(model, test_loader, device)

# """## Save the Model"""

# # Save the trained model
# torch.save(model, 'mobilenet.pth')

